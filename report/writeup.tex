\documentclass[14pt]{article} % For LaTeX2e
\usepackage{amsmath}
\usepackage{verbatim}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{tikz} 
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{subfig}
\usepackage{etex}
\reserveinserts{18}
\usepackage{morefloats}
\usepackage{dsfont}
\usepackage{tikz}
\usepackage[square, numbers]{natbib}
\usepackage[colorlinks,citecolor=red]{hyperref}
%\usepackage{algorithmicx}
%\usepackage{algorithm2e}
\usepackage{algpseudocode}
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\usetikzlibrary{fit,positioning}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollary}

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{ass}{Assumption}[section]
\newtheorem{conj}{Conjecture}[section]
\newtheorem{exmp}{Example}[section]
\newtheorem{exc}{Exercise}[section]


\theoremstyle{remark}
\newtheorem*{rem}{Remark}
\newtheorem*{note}{Note}



\title{MAD Style: Multivalence Authorship Detection (MAD) Topic Models for Stylometric Analysis}

\author{David Dohan, Charles Marsh, Shubhro Saha, Max Simchowitz}
\begin{document}
\maketitle
\large
\begin{abstract}
We draw a lot on \citep{Blei2007}.
\end{abstract}
\section{Introduction}
\section{Literature Review}
\section{Data}
To collect data for training and testing, we wrote scrapers for Project Gutenberg, Quora, and Nassau Weekly. We selected these three data sources for their diversity in topic, language, and length. For example, Project Gutenberg features lengthy narrative texts while Quora features shorter comments in colloquial language. With Nassau Weekly we see a mix: modern prose in a mix of narrative and editorial styles. Because of this diversity, these corpora provide ample training and testing data for our models.

We implemented our scrapers in Python; the full source code can be found in the Supplemental Information section of this report. //TODO: David, write about nature of Gutenberg data. The Quora dataset features about 1600 comments from roughly 100 popular Quora users. The users were selected based on online reports for "most followed" users on the network. Because Quora is a question-answer web site, this content is mostly informative in nature. Depending on the thoroughness of a user's answer, the length can vary from a single word to several paragraphs.

The Nassau Weekly is a student-run humor/culture newspaper. Our dataset features over 550 articles from about 200 authors. The content in this dataset is largely narrative or editorial in nature, and tend to be several paragraphs in length. Interestingly, authors for the publication tend to write in vastly different tones across articles because of the unique, cultish nature of the newspaper. The challenge for our authorship models is to detect consistent features in this dataset across articles by the same author.
\section{Feature Extraction}
\section{Methods}
\section{Evaluation}



\newpage
\bibliography{writeup}
\bibliographystyle{abbrv}

\newpage

\begin{appendix}
\end{appendix}

\end{document}



